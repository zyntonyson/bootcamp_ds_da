{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b62b32c",
   "metadata": {},
   "source": [
    "# ML : Regresi√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7cc074",
   "metadata": {},
   "source": [
    "## Objetivos acad√©micos\n",
    "\n",
    "1. **Comprender los fundamentos de la regresi√≥n en Machine Learning**, diferenciando entre tareas de regresi√≥n y clasificaci√≥n, y reconociendo aplicaciones pr√°cticas de la regresi√≥n.\n",
    "\n",
    "2. **Aplicar y comparar distintos modelos de regresi√≥n** (regresi√≥n lineal, √°rbol de decisi√≥n y random forest) para predecir valores num√©ricos a partir de datos reales.\n",
    "\n",
    "3. **Evaluar el desempe√±o de modelos de regresi√≥n** utilizando m√©tricas como el error cuadr√°tico medio (ECM) y la ra√≠z del error cuadr√°tico medio (RECM), interpretando sus resultados.\n",
    "\n",
    "4. **Optimizar modelos mediante el ajuste de hiperpar√°metros con GridSearchCV**, identificando los par√°metros clave y comprendiendo su impacto en la precisi√≥n y generalizaci√≥n del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94146837",
   "metadata": {},
   "source": [
    "## üü¢ 1. ¬øQu√© es una tarea de regresi√≥n?\n",
    "\n",
    "En Machine Learning, una **tarea de regresi√≥n** consiste en predecir un **valor num√©rico continuo**. A diferencia de la clasificaci√≥n (donde elegimos una categor√≠a como ‚Äúbenigno‚Äù o ‚Äúmaligno‚Äù), aqu√≠ el objetivo es predecir una cantidad: un n√∫mero real.\n",
    "\n",
    "---\n",
    "\n",
    "### üç° Ejemplos del mundo real\n",
    "\n",
    "* ¬øCu√°l ser√° el precio de esta vivienda? üè°  \n",
    "* ¬øCu√°ntas bicicletas se rentar√°n ma√±ana? üö¥‚Äç‚ôÇÔ∏è  \n",
    "* ¬øCu√°nto ganar√° este cliente el pr√≥ximo mes? üíµ  \n",
    "* ¬øQu√© temperatura habr√° la semana que viene? üå°Ô∏è\n",
    "\n",
    "En todos estos casos, no buscamos etiquetar, sino **estimar una cantidad**. Y eso es regresi√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "### üåº Diferencia clave: clasificaci√≥n vs regresi√≥n\n",
    "\n",
    "| Tipo de problema | Objetivo                  | Ejemplo                         |\n",
    "|------------------|---------------------------|----------------------------------|\n",
    "| Clasificaci√≥n    | Predecir una categor√≠a    | ¬øEl tumor es benigno o maligno? |\n",
    "| Regresi√≥n        | Predecir un n√∫mero real   | ¬øCu√°nto cuesta una casa?        |\n",
    "\n",
    "> En resumen: **Clasificaci√≥n = ¬øQu√© clase? / Regresi√≥n = ¬øCu√°nto?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9aedb",
   "metadata": {},
   "source": [
    "## üîµ 2. Nuestro reto: predecir el precio medio de una vivienda en California üè°\n",
    "\n",
    "Vamos a usar un dataset real llamado **California Housing**, que contiene informaci√≥n sobre viviendas y distritos en California. Cada fila representa una zona residencial, y las columnas contienen datos agregados de esa zona.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Caracter√≠sticas del dataset\n",
    "\n",
    "| Columna     | Descripci√≥n                                       |\n",
    "|-------------|---------------------------------------------------|\n",
    "| `MedInc`    | Ingreso medio del distrito (en decenas de miles) |\n",
    "| `HouseAge`  | Antig√ºedad media de las viviendas (en a√±os)      |\n",
    "| `AveRooms`  | N√∫mero promedio de habitaciones por casa         |\n",
    "| `AveOccup`  | Promedio de personas por vivienda                |\n",
    "| `Latitude`  | Latitud del distrito                             |\n",
    "| `Longitude` | Longitud del distrito                            |\n",
    "| `MedHouseVal` | Valor medio de las casas (*target*)           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eecd6ac",
   "metadata": {},
   "source": [
    "### üì• Cargar datos y librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79069678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "df = housing.frame\n",
    "\n",
    "# Separar features y target\n",
    "X = df.drop(columns=['MedHouseVal'])\n",
    "y = df['MedHouseVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ec423",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Preparaci√≥n de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc384e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e0fa0",
   "metadata": {},
   "source": [
    "### üç• ¬øCu√°l es nuestro objetivo?\n",
    "\n",
    "Vamos a construir un modelo que, a partir de variables como el ingreso medio y el n√∫mero de habitaciones, sea capaz de predecir el **valor promedio de una vivienda** en esa zona.\n",
    "\n",
    "* **Entrada (`X`)**: caracter√≠sticas num√©ricas como `MedInc`, `HouseAge`, etc.\n",
    "* **Salida (`y`)**: `MedHouseVal`, el precio medio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc78f6",
   "metadata": {},
   "source": [
    "## üü° 3. ¬øC√≥mo se mide el error en regresi√≥n?\n",
    "\n",
    "En problemas de clasificaci√≥n usamos m√©tricas como *accuracy*, *precision* o *recall* porque las respuestas correctas eran categor√≠as: s√≠/no, A/B, 0/1.\n",
    "\n",
    "Pero en regresi√≥n, **nunca esperamos acertar exactamente el valor real**, sino estar lo m√°s cerca posible.\n",
    "\n",
    "Por eso, las m√©tricas de regresi√≥n se enfocan en medir **qu√© tan lejos** est√°n nuestras predicciones de los valores reales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab01c745",
   "metadata": {},
   "source": [
    "### üç• ¬øQu√© es el *error*?\n",
    "\n",
    "Es simplemente la diferencia entre lo que predice el modelo y el valor correcto:\n",
    "\n",
    "$$\n",
    "\\text{Error} = \\hat{y}_i - y_i\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "* $(\\hat{y}_i)$: es el valor predicho por el modelo para la observaci√≥n $(i)$ \n",
    "* $(y_i)$: es el valor real\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d26d3",
   "metadata": {},
   "source": [
    "### üìÑ Error Cuadr√°tico Medio (ECM / MSE)\n",
    "\n",
    "El ECM mide el promedio de los cuadrados de los errores:\n",
    "\n",
    "$$\n",
    "\\text{ECM} = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2\n",
    "$$\n",
    "\n",
    "**Interpretaci√≥n:**\n",
    "- Penaliza m√°s los errores grandes (porque los eleva al cuadrado).\n",
    "- Siempre es un n√∫mero positivo.\n",
    "- Cuanto m√°s bajo, mejor.\n",
    "\n",
    "> Pero sus unidades son ‚Äúd√≥lares al cuadrado‚Äù si est√°s prediciendo precios, lo cual no es tan intuitivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda8d5ad",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Ra√≠z del ECM (RECM / RMSE)\n",
    "\n",
    "Para volver a las mismas unidades del valor original (por ejemplo, d√≥lares), tomamos la ra√≠z cuadrada del ECM. A esto se le llama:\n",
    "\n",
    "$$\n",
    "\\text{RECM} = \\sqrt{\\text{ECM}}\n",
    "$$\n",
    "\n",
    "**Ejemplo pr√°ctico:**\n",
    "\n",
    "- Si el RECM es `0.45`, significa que en promedio, nos equivocamos unos **$45,000 d√≥lares** (recordando que los valores est√°n en cientos de miles).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c938cd",
   "metadata": {},
   "source": [
    "## üî¥ 4. √Årbol de decisi√≥n para regresi√≥n üå≥\n",
    "\n",
    "Ya vimos que un √°rbol de decisi√≥n funciona como una serie de preguntas del tipo:\n",
    "\n",
    "> ‚Äú¬øEl ingreso medio es mayor a 5.5?‚Äù  \n",
    "> ‚Äú¬øLa antig√ºedad de la vivienda es menor a 20 a√±os?‚Äù\n",
    "\n",
    "En clasificaci√≥n, cada hoja del √°rbol conten√≠a una **clase** (por ejemplo, ‚Äúmaligno‚Äù).  \n",
    "En regresi√≥n, cada hoja contiene un **valor promedio**, calculado con los ejemplos que caen en ese nodo.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Intuici√≥n del √°rbol regresor\n",
    "\n",
    "Un **√°rbol de regresi√≥n** divide el espacio de los datos en regiones donde las predicciones son constantes. Es decir:\n",
    "\n",
    "- Cada regi√≥n termina con un promedio de los valores verdaderos de entrenamiento.\n",
    "- Es como decir: *‚Äúsi el ingreso medio est√° entre 2 y 4 y la ubicaci√≥n es tal, entonces predice \\$120,000‚Äù*.\n",
    "\n",
    "Esto lo convierte en un modelo muy f√°cil de interpretar y visualizar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "preds_tree = tree_reg.predict(X_valid)\n",
    "\n",
    "mse = mean_squared_error(y_valid, preds_tree)\n",
    "rmse = mse ** 0.5\n",
    "print(\"ECM (√Årbol):\", mse)\n",
    "print(\"RECM (√Årbol):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_valid, preds_tree, alpha=0.5)\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], '--r')\n",
    "plt.xlabel(\"Valor real\")\n",
    "plt.ylabel(\"Predicci√≥n\")\n",
    "plt.title(\"√Årbol de decisi√≥n: Real vs Predicci√≥n\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9296457c",
   "metadata": {},
   "source": [
    "> Si los puntos est√°n muy cerca de la l√≠nea roja diagonal (real = predicci√≥n), ¬°vamos por buen camino!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724a766",
   "metadata": {},
   "source": [
    "## üü£ 5. Regresi√≥n Lineal üìà\n",
    "\n",
    "La **regresi√≥n lineal** es uno de los modelos m√°s simples y potentes para predecir valores num√©ricos. A pesar de su simplicidad, muchas veces es sorprendentemente efectiva y es un excelente punto de partida en cualquier problema de regresi√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "### üßæ ¬øQu√© significa ‚Äúlineal‚Äù?\n",
    "\n",
    "Significa que el modelo intenta **ajustar una l√≠nea (o un plano, o un hiperplano)** que se aproxime lo mejor posible a los datos. Esa l√≠nea sigue esta f√≥rmula:\n",
    "\n",
    "$$\n",
    "\\hat{y} = b_0 + b_1 x_1 + b_2 x_2 + \\cdots + b_n x_n\n",
    "$$\n",
    "\n",
    "**Donde:**\n",
    "- $\\hat{y}$ es el valor predicho.\n",
    "- $x_1, x_2, ..., x_n$ son las caracter√≠sticas (por ejemplo, ingreso, habitaciones, edad).\n",
    "- $b_0$ es la intersecci√≥n con el eje y.\n",
    "- $b_1, ..., b_n$ son los coeficientes o **pesos** que determinan la influencia de cada caracter√≠stica.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Intuici√≥n\n",
    "\n",
    "Cada caracter√≠stica ‚Äúempuja‚Äù el valor final hacia arriba o hacia abajo.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "- Si `MedInc` tiene un peso positivo, a mayor ingreso medio, mayor ser√° el precio de la vivienda.\n",
    "- Si `HouseAge` tiene un peso negativo, a mayor antig√ºedad, menor el valor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "preds_lin = lin_reg.predict(X_valid)\n",
    "\n",
    "mse_lin = mean_squared_error(y_valid, preds_lin)\n",
    "rmse_lin = mse_lin ** 0.5\n",
    "print(\"ECM (Lineal):\", mse_lin)\n",
    "print(\"RECM (Lineal):\", rmse_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_valid, preds_lin, alpha=0.5, color=\"orange\")\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], '--r')\n",
    "plt.xlabel(\"Valor real\")\n",
    "plt.ylabel(\"Predicci√≥n\")\n",
    "plt.title(\"Regresi√≥n lineal: Real vs Predicci√≥n\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddbf37d",
   "metadata": {},
   "source": [
    "> Una buena regresi√≥n debe concentrar sus puntos cerca de la l√≠nea roja. Si vemos mucho ‚Äúabanico‚Äù, probablemente necesitamos un modelo m√°s flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e303f96",
   "metadata": {},
   "source": [
    "## üü§ 6. Random Forest para regresi√≥n üå≤\n",
    "\n",
    "Ya trabajamos con:\n",
    "\n",
    "* √Årbol de decisi√≥n, que es f√°cil de interpretar, pero puede sobreajustarse.\n",
    "* Regresi√≥n lineal, que es simple y r√°pida, pero puede no capturar relaciones complejas.\n",
    "\n",
    "Ahora presentamos un modelo que combina **lo mejor de ambos mundos**: el **Random Forest**.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† ¬øQu√© es un Random Forest?\n",
    "\n",
    "Un **bosque aleatorio** es un conjunto de muchos √°rboles de decisi√≥n entrenados con **subconjuntos aleatorios** de los datos y las caracter√≠sticas.\n",
    "\n",
    "> Cada √°rbol hace su predicci√≥n, y el resultado final es el **promedio** de todas las predicciones (en regresi√≥n) o el **voto mayoritario** (en clasificaci√≥n).\n",
    "\n",
    "---\n",
    "\n",
    "### üç• Ventajas del Random Forest\n",
    "\n",
    "‚úÖ Generaliza bien: no se queda atrapado en los datos de entrenamiento.  \n",
    "‚úÖ Maneja relaciones no lineales.  \n",
    "‚úÖ No necesita mucho ajuste.  \n",
    "‚úÖ Resistente al ruido.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Hiperpar√°metros clave\n",
    "\n",
    "* `n_estimators`: n√∫mero de √°rboles en el bosque.\n",
    "* `max_depth`: profundidad m√°xima de cada √°rbol (opcional).\n",
    "* `random_state`: semilla para reproducibilidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "preds_rf = rf_reg.predict(X_valid)\n",
    "\n",
    "mse_rf = mean_squared_error(y_valid, preds_rf)\n",
    "rmse_rf = mse_rf ** 0.5\n",
    "print(\"ECM (RF):\", mse_rf)\n",
    "print(\"RECM (RF):\", rmse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_valid, preds_rf, alpha=0.5, color=\"green\")\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], '--r')\n",
    "plt.xlabel(\"Valor real\")\n",
    "plt.ylabel(\"Predicci√≥n\")\n",
    "plt.title(\"Random Forest: Real vs Predicci√≥n\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b661b",
   "metadata": {},
   "source": [
    "## üìä Comparaci√≥n de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb50f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = ['√Årbol', 'Lineal', 'Random Forest']\n",
    "mse_scores = [mse, mse_lin, mse_rf]\n",
    "rmse_scores = [rmse, rmse_lin, rmse_rf]\n",
    "\n",
    "for modelo, mse_val, rmse_val in zip(modelos, mse_scores, rmse_scores):\n",
    "    print(f\"{modelo}\")\n",
    "    print(f\"  ECM: {mse_val:.4f}\")\n",
    "    print(f\"  RECM: {rmse_val:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c698129",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(modelos))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(x, rmse_scores, tick_label=modelos, color=[\"skyblue\", \"orange\", \"green\"])\n",
    "plt.ylabel(\"RECM\")\n",
    "plt.title(\"Comparaci√≥n de modelos - RECM\")\n",
    "plt.ylim(0, max(rmse_scores) + 0.2)\n",
    "plt.grid(axis='y')\n",
    "plt.xticks(rotation=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da683b36",
   "metadata": {},
   "source": [
    "### üß† ¬øC√≥mo interpretar los resultados?\n",
    "\n",
    "* El modelo con **RECM m√°s bajo** es el que se **equivoca menos** en promedio.\n",
    "* Si el **Random Forest** obtiene el mejor resultado (lo m√°s com√∫n), puedes justificar su elecci√≥n aunque no sea tan interpretable como la regresi√≥n lineal.\n",
    "\n",
    "> Elegir un modelo no siempre es solo por precisi√≥n: a veces se valora tambi√©n la **interpretabilidad**, **velocidad** o **robustez** seg√∫n el contexto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a39c057",
   "metadata": {},
   "source": [
    "## üíæ 8. Guardar el modelo final\n",
    "\n",
    "Una vez que tenemos un modelo bien evaluado (por ejemplo, el **Random Forest** que obtuvo el menor RECM), podemos **guardarlo en un archivo** para:\n",
    "\n",
    "* Reutilizarlo m√°s tarde sin tener que reentrenar.\n",
    "* Integrarlo en una aplicaci√≥n real.\n",
    "* Compartirlo con otros miembros del equipo.\n",
    "* Versionarlo como parte de un flujo de trabajo reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d35429",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf_reg, \"modelo_valor_vivienda.joblib\")\n",
    "\n",
    "# Cargar el modelo desde archivo\n",
    "modelo_cargado = joblib.load(\"modelo_valor_vivienda.joblib\")\n",
    "\n",
    "# Usar el modelo cargado para hacer predicciones\n",
    "nuevas_predicciones = modelo_cargado.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9bc1ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71f1379a",
   "metadata": {},
   "source": [
    "## üß© 9. Ajuste de hiperpar√°metros con GridSearch\n",
    "\n",
    "Para mejorar el rendimiento de un modelo como Random Forest, es fundamental ajustar sus hiperpar√°metros, es decir, aquellos valores que controlan el comportamiento del algoritmo (por ejemplo, el n√∫mero de √°rboles, la profundidad m√°xima, etc.). Una t√©cnica muy utilizada es **GridSearch**, que consiste en probar de manera sistem√°tica todas las combinaciones posibles de un conjunto de valores para los hiperpar√°metros seleccionados. Usando `GridSearchCV` de `scikit-learn`, podemos automatizar este proceso: el m√©todo entrena y valida el modelo con cada combinaci√≥n, utilizando validaci√≥n cruzada, y al final nos indica cu√°l es la mejor configuraci√≥n seg√∫n la m√©trica elegida (por ejemplo, el menor RECM). As√≠, GridSearch nos ayuda a encontrar el modelo m√°s preciso de forma eficiente y reproducible.\n",
    "\n",
    "\n",
    "\n",
    "### üîß Principales hiperpar√°metros para ajustar en Random Forest\n",
    "\n",
    "Al utilizar GridSearch para optimizar un modelo Random Forest, es importante considerar los hiperpar√°metros m√°s relevantes que influyen en su desempe√±o. Entre los principales se encuentran:\n",
    "\n",
    "- **`n_estimators`**: n√∫mero de √°rboles en el bosque. M√°s √°rboles suelen mejorar la precisi√≥n, pero aumentan el tiempo de c√≥mputo.\n",
    "- **`max_depth`**: profundidad m√°xima de cada √°rbol. Limitarla ayuda a evitar el sobreajuste.\n",
    "- **`min_samples_split`**: n√∫mero m√≠nimo de muestras necesarias para dividir un nodo interno.\n",
    "- **`min_samples_leaf`**: n√∫mero m√≠nimo de muestras requeridas en una hoja.\n",
    "- **`max_features`**: n√∫mero m√°ximo de caracter√≠sticas consideradas al buscar la mejor divisi√≥n en cada nodo.\n",
    "- **`bootstrap`**: indica si se usan muestras con reemplazo para construir los √°rboles.\n",
    "- **`random_state`**: semilla para asegurar la reproducibilidad de los resultados.\n",
    "\n",
    "Ajustar estos hiperpar√°metros permite encontrar el equilibrio √≥ptimo entre precisi√≥n, generalizaci√≥n y eficiencia computacional del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir el diccionario de hiperpar√°metros a probar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 3],\n",
    "    'max_features': ['log2', 'sqrt']\n",
    "}\n",
    "\n",
    "# Crear el modelo base\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='neg_root_mean_squared_error',  # Para minimizar el RECM\n",
    "    n_jobs=-1,  # Usar todos los n√∫cleos disponibles\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ajustar el modelo\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperpar√°metros encontrados\n",
    "print(\"Mejores hiperpar√°metros:\", grid_search.best_params_)\n",
    "print(\"Mejor RECM (validaci√≥n cruzada):\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd91685",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gridsearch = grid_search.best_estimator_\n",
    "predict_gridsearch = best_gridsearch.predict(X_valid)\n",
    "mse_rf = mean_squared_error(y_valid, predict_gridsearch)\n",
    "rmse_rf = mse_rf ** 0.5\n",
    "print(\"ECM (RF):\", mse_rf)\n",
    "print(\"RECM (RF):\", rmse_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_valid, predict_gridsearch, alpha=0.5, color=\"green\")\n",
    "plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], '--r')\n",
    "plt.xlabel(\"Valor real\")\n",
    "plt.ylabel(\"Predicci√≥n\")\n",
    "plt.title(\"Random Forest GridSearch: Real vs Predicci√≥n\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21eba46",
   "metadata": {},
   "source": [
    "# En resumen\n",
    "\n",
    "1. **Regresi√≥n :**  Es una tarea donde el objetivo es predecir valores num√©ricos continuos, a diferencia de la clasificaci√≥n que predice categor√≠as.\n",
    "\n",
    "2. **M√©tricas de evaluaci√≥n:** : El error cuadr√°tico medio (ECM) y la ra√≠z del error cuadr√°tico medio (RECM) son m√©tricas clave para medir la precisi√≥n de los modelos de regresi√≥n.\n",
    "\n",
    "3. **Ajuste de hiperpar√°metros:** :El uso de GridSearchCV permite encontrar la mejor combinaci√≥n de hiperpar√°metros para mejorar el rendimiento del modelo, especialmente en random forest.\n",
    "\n",
    "4. **Interpretaci√≥n y visualizaci√≥n de resultados:** : Analizar gr√°ficamente las predicciones frente a los valores reales ayuda a identificar el ajuste del modelo y posibles √°reas de mejora.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
